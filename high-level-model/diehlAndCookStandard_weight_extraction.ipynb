{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting program\")\n",
    "import os\n",
    "from time import time as t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_assignments,\n",
    "    plot_input,\n",
    "    plot_performance,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.learning import PostPre\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import DiehlAndCookNodes, Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection, LocalConnection\n",
    "from typing import Iterable, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "seed = 0\n",
    "n_epochs = 1\n",
    "n_test = 10000\n",
    "n_train = 60000\n",
    "batch_size = 1\n",
    "n_neurons = 100\n",
    "padding = 0\n",
    "time = 50\n",
    "dt = 1.0\n",
    "intensity = 128.0\n",
    "progress_interval = 10\n",
    "update_interval = 250\n",
    "train = True\n",
    "plot = False#True\n",
    "gpu = True\n",
    "n_classes = 10\n",
    "n_workers = -1\n",
    "exc = 22.5\n",
    "inh = 120\n",
    "theta_plus = 0.05\n",
    "\n",
    "\n",
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "# Determines number of workers to use\n",
    "if n_workers == -1:\n",
    "    n_workers = 0  # gpu * 4 * torch.cuda.device_count()\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "\n",
    "class DiehlAndCook2015Standard(Network):\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Implements the spiking neural network architecture from `(Diehl & Cook 2015)\n",
    "    <https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full>`_.\n",
    "    Standard learning algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_inpt: int,\n",
    "        n_neurons: int = 100,\n",
    "        exc: float = 22.5,\n",
    "        inh: float = 17.5,\n",
    "        dt: float = 1.0,\n",
    "        nu: Optional[Union[float, Sequence[float]]] = (1e-4, 1e-2),\n",
    "        reduction: Optional[callable] = None,\n",
    "        wmin: float = 0.0,\n",
    "        wmax: float = 1.0,\n",
    "        norm: float = 78.4,\n",
    "        theta_plus: float = 0.05,\n",
    "        tc_theta_decay: float = 1e7,\n",
    "        inpt_shape: Optional[Iterable[int]] = None,\n",
    "        inh_thresh: float = -40.0,\n",
    "        exc_thresh: float = -52.0,\n",
    "    ) -> None:\n",
    "        # language=rst\n",
    "        \"\"\"\n",
    "        Constructor for class ``DiehlAndCook2015``.\n",
    "\n",
    "        :param n_inpt: Number of input neurons. Matches the 1D size of the input data.\n",
    "        :param n_neurons: Number of excitatory, inhibitory neurons.\n",
    "        :param exc: Strength of synapse weights from excitatory to inhibitory layer.\n",
    "        :param inh: Strength of synapse weights from inhibitory to excitatory layer.\n",
    "        :param dt: Simulation time step.\n",
    "        :param nu: Single or pair of learning rates for pre- and post-synaptic events,\n",
    "            respectively.\n",
    "        :param reduction: Method for reducing parameter updates along the minibatch\n",
    "            dimension.\n",
    "        :param wmin: Minimum allowed weight on input to excitatory synapses.\n",
    "        :param wmax: Maximum allowed weight on input to excitatory synapses.\n",
    "        :param norm: Input to excitatory layer connection weights normalization\n",
    "            constant.\n",
    "        :param theta_plus: On-spike increment of ``DiehlAndCookNodes`` membrane\n",
    "            threshold potential.\n",
    "        :param tc_theta_decay: Time constant of ``DiehlAndCookNodes`` threshold\n",
    "            potential decay.\n",
    "        :param inpt_shape: The dimensionality of the input layer.\n",
    "        \"\"\"\n",
    "        super().__init__(dt=dt)\n",
    "\n",
    "        self.n_inpt = n_inpt\n",
    "        self.inpt_shape = inpt_shape\n",
    "        self.n_neurons = n_neurons\n",
    "        self.exc = exc\n",
    "        self.inh = inh\n",
    "        self.dt = dt\n",
    "\n",
    "        # Layers\n",
    "        input_layer = Input(\n",
    "            n=self.n_inpt, shape=self.inpt_shape, traces=True, tc_trace=20.0\n",
    "        )\n",
    "        exc_layer = DiehlAndCookNodes(\n",
    "            n=self.n_neurons,\n",
    "            traces=True,\n",
    "            rest=-65.0,\n",
    "            reset=-60.0,\n",
    "            thresh=exc_thresh,\n",
    "            refrac=5,\n",
    "            tc_decay=100.0,\n",
    "            tc_trace=20.0,\n",
    "            theta_plus=theta_plus,\n",
    "            tc_theta_decay=tc_theta_decay,\n",
    "        )\n",
    "        inh_layer = LIFNodes(\n",
    "            n=self.n_neurons,\n",
    "            traces=False,\n",
    "            rest=-60.0,\n",
    "            reset=-45.0,\n",
    "            thresh=inh_thresh,\n",
    "            tc_decay=10.0,\n",
    "            refrac=2,\n",
    "            tc_trace=20.0,\n",
    "        )\n",
    "\n",
    "        # Connections\n",
    "        w = 0.3 * torch.rand(self.n_inpt, self.n_neurons)\n",
    "        input_exc_conn = Connection(\n",
    "            source=input_layer,\n",
    "            target=exc_layer,\n",
    "            w=w,\n",
    "            update_rule=PostPre,\n",
    "            nu=nu,\n",
    "            reduction=reduction,\n",
    "            wmin=wmin,\n",
    "            wmax=wmax,\n",
    "            norm=norm,\n",
    "        )\n",
    "        w = self.exc * torch.diag(torch.ones(self.n_neurons))\n",
    "        exc_inh_conn = Connection(\n",
    "            source=exc_layer, target=inh_layer, w=w, wmin=0, wmax=self.exc\n",
    "        )\n",
    "        w = -self.inh * (\n",
    "            torch.ones(self.n_neurons, self.n_neurons)\n",
    "            - torch.diag(torch.ones(self.n_neurons))\n",
    "        )\n",
    "        inh_exc_conn = Connection(\n",
    "            source=inh_layer, target=exc_layer, w=w, wmin=-self.inh, wmax=0\n",
    "        )\n",
    "\n",
    "        # Add to network\n",
    "        self.add_layer(input_layer, name=\"X\")\n",
    "        self.add_layer(exc_layer, name=\"Ae\")\n",
    "        self.add_layer(inh_layer, name=\"Ai\")\n",
    "        self.add_connection(input_exc_conn, source=\"X\", target=\"Ae\")\n",
    "        self.add_connection(exc_inh_conn, source=\"Ae\", target=\"Ai\")\n",
    "        self.add_connection(inh_exc_conn, source=\"Ai\", target=\"Ae\")\n",
    "\n",
    "\n",
    "# Build network.\n",
    "network = DiehlAndCook2015Standard(\n",
    "    n_inpt=784,\n",
    "    n_neurons=100 ,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")\n",
    "\n",
    "# Load MNIST data.\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    \"cluster/home/thombruf/MNIST\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "n_classes = 10\n",
    "assignments = -torch.ones(n_neurons, device=device)\n",
    "proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros((n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "inh_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device\n",
    "    )\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device\n",
    "    )\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
    "\n",
    "inpt_ims, inpt_axes = None, None\n",
    "spike_ims, spike_axes = None, None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes, voltage_ims = None, None\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin training.\\n\")\n",
    "\n",
    "start = t()\n",
    "for epoch in range(n_epochs):\n",
    "    labels = []\n",
    "\n",
    "    if epoch % progress_interval == 0:\n",
    "        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
    "        start = t()\n",
    "\n",
    "    # Create a dataloader to iterate and batch data\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu\n",
    "    )\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        if step > n_train:\n",
    "            break\n",
    "        # Get next input sample.\n",
    "        inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "        if gpu:\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "        if step % update_interval == 0 and step > 0:\n",
    "            # Convert the array of labels into a tensor\n",
    "            label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "            # Get network predictions.\n",
    "            all_activity_pred = all_activity(\n",
    "                spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "            )\n",
    "            proportion_pred = proportion_weighting(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                proportions=proportions,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "\n",
    "            # Compute network accuracy according to available classification strategies.\n",
    "            accuracy[\"all\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "            \n",
    "            accuracy[\"proportion\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "                % (\n",
    "                    accuracy[\"all\"][-1],\n",
    "                    np.mean(accuracy[\"all\"]),\n",
    "                    np.max(accuracy[\"all\"]),\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "                \" (best)\\n\"\n",
    "                % (\n",
    "                    accuracy[\"proportion\"][-1],\n",
    "                    np.mean(accuracy[\"proportion\"]),\n",
    "                    np.max(accuracy[\"proportion\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Assign labels to excitatory layer neurons.\n",
    "            assignments, proportions, rates = assign_labels(\n",
    "                spikes=spike_record,\n",
    "                labels=label_tensor,\n",
    "                n_labels=n_classes,\n",
    "                rates=rates,\n",
    "            )\n",
    "\n",
    "            labels = []\n",
    "\n",
    "        labels.append(batch[\"label\"])\n",
    "\n",
    "        # Run the network on the input.\n",
    "        network.run(inputs=inputs, time=time)\n",
    "\n",
    "        # Get voltage recording.\n",
    "        exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "        inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "        # Add to spikes recording.\n",
    "        spike_record[step % update_interval] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "        # Optionally plot various simulation information.\n",
    "        if plot:\n",
    "            voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "            voltage_ims, voltage_axes = plot_voltages(\n",
    "                voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\"\n",
    "            )\n",
    "\n",
    "            plt.pause(1e-8)\n",
    "\n",
    "        network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Training complete.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#network.save(file_name=\"Standard_network_Diehl_and_Cook_100_neurons\")\n",
    "network.save(str(Path.home()) + '/Standard_network_Diehl_and_Cook_100_neurons.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Trained weights:\")\n",
    "print(\"\\n\")\n",
    "print(\"Weights between input and excitatory layer:\")\n",
    "print(network.connections[(\"X\", \"Ae\")].w)\n",
    "print(\"\\n\")\n",
    "print(\"Weights between excitatory and inhibitory layer:\")\n",
    "print(network.connections[(\"Ae\", \"Ai\")].w)\n",
    "print(\"\\n\")\n",
    "print(\"Weights between inhibitory and excitatory layer:\")\n",
    "print(network.connections[(\"Ai\", \"Ae\")].w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('conn_X_Ae.txt', network.connections[(\"X\", \"Ae\")].w.numpy())\n",
    "np.savetxt('conn_Ae_Ai.txt', network.connections[(\"Ae\", \"Ai\")].w.numpy())\n",
    "np.savetxt('conn_Ai_Ae.txt', network.connections[(\"Ai\", \"Ae\")].w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is code to extract neuron assignments to know which neurons correspond to which label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assignments: \", assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proportions: \", proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rates: \", rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained weights lengths:\")\n",
    "print(\"\\n\")\n",
    "print(\"Length of weights between input and excitatory layer:\")\n",
    "print(network.connections[(\"X\", \"Ae\")].w.numpy().shape)\n",
    "print(\"\\n\")\n",
    "print(\"Length of weights between excitatory and inhibitory layer:\")\n",
    "print(network.connections[(\"Ae\", \"Ai\")].w.numpy().shape)\n",
    "print(\"\\n\")\n",
    "print(\"Length of weights between inhibitory and excitatory layer:\")\n",
    "print(network.connections[(\"Ai\", \"Ae\")].w.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to get the threshold from all the neurons extracted so that I can set them in hardware from file.\n",
    "print(network.layers[\"Ae\"].thresh.numpy())\n",
    "print(network.layers[\"Ae\"].thresh.numpy().shape)\n",
    "print(network.layers[\"Ae\"].theta.numpy())\n",
    "print(network.layers[\"Ae\"].theta.numpy().shape)\n",
    "for theta in network.layers[\"Ae\"].theta.numpy():\n",
    "    print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in network.layers[\"Ae\"].theta.numpy():\n",
    "    new_thresh = -52.0+theta\n",
    "    print(new_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Training complete.\\n\")\n",
    "\n",
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    \"cluster/home/thombruf/MNIST\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "inh_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "\n",
    "exc_spikes_monitor = Monitor(\n",
    "    network.layers[\"Ae\"], state_vars=[\"s\"], time=int(time / dt), device=device\n",
    ")\n",
    "\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "network.add_monitor(exc_spikes_monitor, name=\"exc_spikes\")\n",
    "\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
    "spikes_sum = torch.zeros((1, n_neurons))\n",
    "\n",
    "# Test the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "start = t()\n",
    "\n",
    "counter = 0\n",
    "spike_counter = 0\n",
    "max_voltage_prints = 3\n",
    "max_spike_prints = 3\n",
    "k = 10000\n",
    "input_spike_trains_list = []\n",
    "\n",
    "#pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step >= n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    # Iterate over the dataset and print the encoded spike trains\n",
    "    if step < k:  # Change this number to print more or fewer samples\n",
    "        spike_trains = batch[\"encoded_image\"]  # Access the encoded spike trains\n",
    "    \n",
    "        label = batch['label']\n",
    "    \n",
    "        # Initialize recorded_spikes with the correct dimensions\n",
    "        recorded_spikes = [[0] * 50 for _ in range(28 * 28)]  # 28*28 = 784 for MNIST images\n",
    "    \n",
    "        for time_step in range(spike_trains.shape[0]):  # 50 time steps\n",
    "            # Flatten the 28x28 image to a 784-length vector for the current time step\n",
    "            flat_image = spike_trains[time_step].flatten()\n",
    "    \n",
    "            # Store the spikes for each pixel at the current time step\n",
    "            for pixel_index in range(len(flat_image)):\n",
    "\n",
    "                recorded_spikes[pixel_index][time_step] = flat_image[pixel_index].item()\n",
    "        input_spike_trains_list.append(recorded_spikes)\n",
    "    \n",
    "    if gpu:\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=time)\n",
    "    \n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "    exc_spikes = exc_spikes_monitor.get(\"s\")\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    spikes_sum += spike_record.sum(1)\n",
    "    \n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(\n",
    "        spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "    )\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(\n",
    "        torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "    )\n",
    "    \n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
    "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Testing complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(exc_spikes))\n",
    "print((exc_spikes.shape))\n",
    "print(exc_spikes[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Add this here so that I can analyze the last image sent in - useful for just seeing the behaviour of the top level SNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_input_spikes_for_one_image(input_spike_trains_list, output_file_path):\n",
    "    try:\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                for recorded_spikes in input_spike_trains_list:\n",
    "                    for recorded_pixel_spike_train in recorded_spikes:\n",
    "                        f.write(\"[\")\n",
    "                        f.write(\",\".join(map(str, recorded_pixel_spike_train)))\n",
    "                        f.write(\"]\")\n",
    "                        f.write(\"\\n\")\n",
    "    except:\n",
    "        print(\"Could not save input spike trains to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_input_spikes_for_one_image(input_spike_trains_list=input_spike_trains_list, output_file_path=\"input_spikes_full_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in exc_voltage_monitor:\n",
    "    print(exc_voltage_monitor[key])\n",
    "for key in inh_voltage_monitor:\n",
    "    print(inh_voltage_monitor[key])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(time):\n",
    "    print(\"Time step: \", t)\n",
    "    print(exc_voltages[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in network.layers[\"Ae\"].theta.numpy():\n",
    "    print(theta)\n",
    "    print(theta-52.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.image_encoder.enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataset and print the encoded spike trains\n",
    "for i in range(len(test_dataset)):\n",
    "    data = test_dataset[i]  # Get the i-th sample\n",
    "    spike_trains = data['encoded_image']  # Access the encoded spike trains\n",
    "\n",
    "    recorded_spikes = [[0]*250 for i in range(784)]\n",
    "    print(recorded_spikes)\n",
    "    pixel_at_index = []\n",
    "    total_sum = 0\n",
    "    for image_matrix in spike_trains:\n",
    "        for k in range(len(image_matrix)):\n",
    "            flat_image = image_matrix[k].flatten()\n",
    "            for i in range(len(flat_image)):\n",
    "                recorded_spikes[i][k] = flat_image[i].item()\n",
    "\n",
    "            if (sum(image_matrix[k].flatten()) > 0):\n",
    "                print(sum(image_matrix[k].flatten()).item())\n",
    "                total_sum += sum(image_matrix[k].flatten()).item()\n",
    "    print(total_sum) \n",
    "    print(pixel_at_index)\n",
    "    print(len(recorded_spikes))\n",
    "    print(len(recorded_spikes[0]))\n",
    "    print(recorded_spikes)\n",
    "    for index, array in enumerate(recorded_spikes):\n",
    "        if (sum(array)):\n",
    "            print(\"The number of spikes at this pixel \", index, \" was: \", sum(array))\n",
    "            print(\"This spike happened at the time step: \", np.argmax(np.array(array)))\n",
    "\n",
    "\n",
    "    # Optional: break after a few iterations to avoid too much output\n",
    "    if i >= 0:  # Change this number to print more or fewer samples\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=50, dt=dt),\n",
    "    None,\n",
    "    \"cluster/home/thombruf/MNIST\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataset and print the encoded spike trains\n",
    "k = 0#100\n",
    "input_spike_trains_list = []\n",
    "for i in range(0,len(test_dataset)):\n",
    "    data = test_dataset[i]  # Get the i-th sample\n",
    "    spike_trains = data['encoded_image']  # Access the encoded spike trains\n",
    "    label = data['label']\n",
    "    print(\"Label for this image: \", label)\n",
    "\n",
    "    # Initialize recorded_spikes with the correct dimensions\n",
    "    recorded_spikes = [[0] * 50 for _ in range(28 * 28)]  # 28*28 = 784 for MNIST images\n",
    "   \n",
    "    for t in range(spike_trains.shape[0]):  # 50 time steps\n",
    "        # Flatten the 28x28 image to a 784-length vector for the current time step\n",
    "        flat_image = spike_trains[t].flatten()\n",
    "        if (t == 0):\n",
    "            print(flat_image)\n",
    "        \n",
    "        # Store the spikes for each pixel at the current time step\n",
    "        for pixel_index in range(len(flat_image)):\n",
    "            if (flat_image[pixel_index]):\n",
    "                print(\"Index in flat image with spike: \", pixel_index)\n",
    "                print(\"Timestep: \", t)\n",
    "            recorded_spikes[pixel_index][t] = flat_image[pixel_index].item()\n",
    "    input_spike_trains_list.append(recorded_spikes)\n",
    "\n",
    "\n",
    "    total_spike_count_for_this_image = 0\n",
    "    for index, spike_recording in enumerate(recorded_spikes):\n",
    "        if (sum(spike_recording)):\n",
    "            total_spike_count_for_this_image += sum(spike_recording)\n",
    "\n",
    "    # Optional: break after a few iterations to avoid too much output\n",
    "    if i >= k:  # Change this number to print more or fewer samples\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_input_spikes_for_one_image(input_spike_trains_list, output_file_path):\n",
    "    try:\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                for recorded_spikes in input_spike_trains_list:\n",
    "                    for recorded_pixel_spike_train in recorded_spikes:\n",
    "                        f.write(\"[\")\n",
    "                        f.write(\",\".join(map(str, recorded_pixel_spike_train)))\n",
    "                        f.write(\"]\")\n",
    "                        f.write(\"\\n\")\n",
    "    except:\n",
    "        print(\"Could not save input spike trains to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_input_spikes_for_one_image(input_spike_trains_list=input_spike_trains_list, output_file_path=\"input_spike_trains_dense.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_assignments = [9, 2, 7, 6, 9, 4, 0, 5, 8, 4, 9, 8, 0, 2, 2, 8, 9, 8, 3, 5, 0, 4, 6, 9,\n",
    "        0, 7, 9, 0, 3, 8, 2, 2, 6, 9, 6, 9, 8, 8, 0, 2, 6, 2, 8, 8, 3, 8, 3, 3,\n",
    "        4, 9, 0, 0, 4, 0, 5, 8, 3, 0, 4, 5, 6, 0, 3, 0, 7, 6, 3, 1, 7, 0, 6, 8,\n",
    "        3, 4, 4, 3, 3, 9, 5, 8, 3, 6, 1, 3, 5, 8, 1, 9, 6, 8, 7, 5, 3, 2, 0, 1,\n",
    "        7, 7, 5, 8]\n",
    "print(new_assignments.count(9))\n",
    "print(new_assignments.count(8))\n",
    "print(new_assignments.count(7))\n",
    "print(new_assignments.count(6))\n",
    "print(new_assignments.count(5))\n",
    "print(new_assignments.count(4))\n",
    "print(new_assignments.count(3))\n",
    "print(new_assignments.count(2))\n",
    "print(new_assignments.count(1))\n",
    "print(new_assignments.count(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
